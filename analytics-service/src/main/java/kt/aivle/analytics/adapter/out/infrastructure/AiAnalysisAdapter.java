package kt.aivle.analytics.adapter.out.infrastructure;

import java.util.List;
import java.util.Map;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.HttpEntity;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.client.RestTemplate;

import kt.aivle.analytics.adapter.out.infrastructure.dto.AiReportRequest;
import kt.aivle.analytics.adapter.out.infrastructure.dto.AiReportResponse;
import kt.aivle.analytics.application.port.out.dto.AiAnalysisRequest;
import kt.aivle.analytics.application.port.out.dto.AiAnalysisResponse;
import kt.aivle.analytics.application.port.out.infrastructure.AiAnalysisPort;
import kt.aivle.analytics.application.port.out.repository.PostCommentKeywordRepositoryPort;
import kt.aivle.analytics.domain.entity.SnsPostCommentMetric;
import kt.aivle.analytics.domain.model.SentimentType;
import kt.aivle.analytics.exception.AnalyticsErrorCode;
import kt.aivle.common.exception.BusinessException;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;

@Slf4j
@Component
@RequiredArgsConstructor
public class AiAnalysisAdapter implements AiAnalysisPort {
    
    private final RestTemplate restTemplate;
    private final PostCommentKeywordRepositoryPort keywordRepository;
    
    @Value("${ai.origin-url}")
    private String aiOriginUrl;
    
    // ì²˜ë¦¬ ì¤‘ì¸ AI ë¶„ì„ ì‘ì—…ì„ ì¶”ì í•˜ëŠ” ìºì‹œ
    private final Map<Long, CompletableFuture<AiReportResponse>> processingTasks = new ConcurrentHashMap<>();
    
    @Override
    public AiAnalysisResponse analyzeComments(List<SnsPostCommentMetric> comments, Long postId) {
        try {
            // ê¸°ì¡´ í‚¤ì›Œë“œë¥¼ ê°ì •ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¡°íšŒ
            Map<SentimentType, List<String>> groupedKeywords = keywordRepository.findKeywordsByPostIdGroupedBySentiment(postId);
            
            List<String> positiveKeywords = groupedKeywords.getOrDefault(SentimentType.POSITIVE, List.of());
            List<String> negativeKeywords = groupedKeywords.getOrDefault(SentimentType.NEGATIVE, List.of());
            
            // ìš”ì²­ ë°ì´í„° êµ¬ì„±
            List<AiAnalysisRequest.CommentData> commentDataList = comments.stream()
                .map(comment -> AiAnalysisRequest.CommentData.builder()
                    .id(comment.getId())
                    .created_at(comment.getCreatedAt().toString())
                    .author_id(comment.getAuthorId())
                    .content(comment.getContent())
                    .like_count(comment.getLikeCount().intValue())
                    .post_id(comment.getPostId())
                    .published_at(comment.getPublishedAt().toString())
                    .sns_comment_id(comment.getSnsCommentId())
                    .build())
                .collect(Collectors.toList());
            
            AiAnalysisRequest.Keywords keywords = AiAnalysisRequest.Keywords.builder()
                .positive(positiveKeywords)
                .negative(negativeKeywords)
                .build();
            
            AiAnalysisRequest request = AiAnalysisRequest.builder()
                .comments(commentDataList)
                .keywords(keywords)
                .build();
            
            // HTTP í—¤ë” ì„¤ì •
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_JSON);
            
            HttpEntity<AiAnalysisRequest> entity = new HttpEntity<>(request, headers);
            
            String analysisUrl = aiOriginUrl + "/api/comments/analyze";
            log.info("ğŸš€ AI ì„œë²„ ìš”ì²­ ì‹œì‘ - URL: {}, ëŒ“ê¸€ ìˆ˜: {}, ê¸ì • í‚¤ì›Œë“œ: {}, ë¶€ì • í‚¤ì›Œë“œ: {}", 
                analysisUrl, comments.size(), positiveKeywords.size(), negativeKeywords.size());
            
            // AI ë¶„ì„ ì„œë²„ í˜¸ì¶œ
            log.info("ğŸ“¤ AI ì„œë²„ë¡œ ìš”ì²­ ì „ì†¡ ì¤‘...");
            AiAnalysisResponse response = restTemplate.postForObject(analysisUrl, entity, AiAnalysisResponse.class);
            log.info("ğŸš€ AI ì„œë²„ ì‘ë‹µ: {}", response);

            if (response.getIndividual_results() == null) {
                log.error("âŒ AI ì„œë²„ ì‘ë‹µì˜ individual_resultsê°€ nullì…ë‹ˆë‹¤");
                throw new BusinessException(AnalyticsErrorCode.AI_ANALYSIS_ERROR);
            }
            
            log.info("âœ… AI ë¶„ì„ ì™„ë£Œ - ëŒ“ê¸€ ìˆ˜: {}, ì‘ë‹µ ìƒíƒœ: ì„±ê³µ", comments.size());
            return response;
            
        } catch (Exception e) {
            log.error("Failed to analyze comments with AI service: {}", e.getMessage());
            throw new BusinessException(AnalyticsErrorCode.AI_ANALYSIS_ERROR);
        }
    }
    
    @Override
    public AiReportResponse generateReport(AiReportRequest request, Long storeId) {
        Long postId = request.getMetrics().getPost_id();
        
        try {
            // 1. ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
            CompletableFuture<AiReportResponse> existingTask = processingTasks.get(postId);
            if (existingTask != null && !existingTask.isDone()) {
                log.info("ğŸ”„ [AI] Already processing postId: {}, waiting for existing task", postId);
                try {
                    return existingTask.get(5, TimeUnit.MINUTES); // ê¸°ì¡´ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
                } catch (Exception e) {
                    log.warn("Existing task failed for postId: {}, starting new one", postId);
                    processingTasks.remove(postId);
                }
            }
            
            // 2. ìƒˆ ì‘ì—… ì‹œì‘
            CompletableFuture<AiReportResponse> newTask = CompletableFuture.supplyAsync(() -> {
                try {
                    return callAiService(request, storeId);
                } finally {
                    processingTasks.remove(postId); // ì™„ë£Œ í›„ ì œê±°
                }
            });
            
            processingTasks.put(postId, newTask);
            
            log.info("ğŸ¤– [AI] Starting new analysis - postId: {}, title: {}", postId, request.getTitle());
            
            return newTask.get(5, TimeUnit.MINUTES);
            
        } catch (Exception e) {
            processingTasks.remove(postId);
            log.error("âŒ [AI] Failed - postId: {}, error: {}", postId, e.getMessage());
            throw new BusinessException(AnalyticsErrorCode.AI_ANALYSIS_ERROR);
        }
    }
    
    private AiReportResponse callAiService(AiReportRequest request, Long storeId) {
        try {
            // HTTP í—¤ë” ì„¤ì •
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_JSON);
            
            HttpEntity<AiReportRequest> entity = new HttpEntity<>(request, headers);
            
            String reportUrl = aiOriginUrl + "/api/analysis/report";
            
            // AI ë³´ê³ ì„œ ìƒì„± ì„œë²„ í˜¸ì¶œ
            AiReportResponse response = restTemplate.postForObject(reportUrl, entity, AiReportResponse.class);
            
            if (response == null || response.getMarkdown_report() == null) {
                log.error("âŒ [AI] Response is null or markdown_report is null");
                throw new BusinessException(AnalyticsErrorCode.AI_ANALYSIS_ERROR);
            }
            
            log.info("âœ… [AI] Received response - postId: {}", request.getMetrics().getPost_id());
            return response;
            
        } catch (Exception e) {
            log.error("âŒ [AI] Failed - postId: {}, error: {}", 
                    request.getMetrics().getPost_id(), e.getMessage());
            throw new BusinessException(AnalyticsErrorCode.AI_ANALYSIS_ERROR);
        }
    }
}
